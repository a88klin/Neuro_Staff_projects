{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p390H6H72bR6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Генерация продающего заголовка на основании информации об услугах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mt1kzuSLWgQz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install openai langchain langchain_openai langchain-community tiktoken faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1466,
     "status": "ok",
     "timestamp": 1709146447768,
     "user": {
      "displayName": "Alex Klin",
      "userId": "11249935885368047783"
     },
     "user_tz": -180
    },
    "id": "aUCyyZ2Vgeik",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import openai\n",
    "import tiktoken\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import Document, RecursiveCharacterTextSplitter\n",
    "from google.colab import userdata\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "MODEL = 'gpt-3.5-turbo-0125'\n",
    "TOTAL_AMOUNT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 579,
     "status": "ok",
     "timestamp": 1709146538453,
     "user": {
      "displayName": "Alex Klin",
      "userId": "11249935885368047783"
     },
     "user_tz": -180
    },
    "id": "gnW5pSUimDFb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Функция загружает plane text из ГуглДока по URL-ссылке (url)\n",
    "def load_googledoc_by_url(url: str) -> str:\n",
    "        match_ = re.search('/document/d/([a-zA-Z0-9-_]+)', url)\n",
    "        if match_ is None:\n",
    "            raise ValueError('Invalid Google Docs URL')\n",
    "        doc_id = match_.group(1)\n",
    "        response = requests.get(f'https://docs.google.com/document/d/{doc_id}/export?format=txt')\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "\n",
    "\n",
    "# функция добавления переходов на новую строку для удобства чтения\n",
    "def format_newlines(text: str, max_len: int = 150) -> str:\n",
    "    lines = text.splitlines()\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        words = line.split()\n",
    "        current_line = \"\"\n",
    "        for word in words:\n",
    "            if len(current_line + \" \" + word) > max_len:\n",
    "                new_lines.append(current_line)\n",
    "                current_line = \"\"\n",
    "            current_line += f' {word}'\n",
    "        new_lines.append(current_line)\n",
    "    return \"\\n\".join(new_lines)\n",
    "\n",
    "\n",
    "# функция подсчета токенов\n",
    "def num_tokens_from_messages(messages, model):\n",
    "      \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "      try:\n",
    "          encoding = tiktoken.encoding_for_model(model)\n",
    "      except KeyError:\n",
    "          encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "      if model in [\"gpt-3.5-turbo-0125\"]:  # note: future models may deviate from this\n",
    "          num_tokens = 0\n",
    "          for message in messages:\n",
    "              num_tokens += 4  # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "              for key, value in message.items():\n",
    "                  num_tokens += len(encoding.encode(value))\n",
    "                  if key == \"name\":  # if there's a name, the role is omitted\n",
    "                      num_tokens += -1  # role is always required and always 1 token\n",
    "          num_tokens += 2  # every reply is primed with <im_start>assistant\n",
    "          return num_tokens\n",
    "      else:\n",
    "          raise NotImplementedError(f'Num_tokens_from_messages() is not presently implemented for model {model}.')\n",
    "\n",
    "\n",
    "# Подсчет токенов в строке\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    return len(encoding.encode(string))\n",
    "\n",
    "\n",
    "# функция создания индексов БЗ\n",
    "def create_search_index(file_text, knowledge_base_link, chunk_size=1024, chunk_overlap=200):\n",
    "    splitter = RecursiveCharacterTextSplitter(['\\n\\n', '\\n', ' '],\n",
    "                                              chunk_size=chunk_size,\n",
    "                                              chunk_overlap=chunk_overlap)\n",
    "    count_tokens = 0\n",
    "    source_chunks = []\n",
    "    # разбиваем на несколько частей с помощью метода split_text\n",
    "    for chunkID, chunk in enumerate(splitter.split_text(file_text)):\n",
    "        source_chunks.append(Document(page_content=chunk, \\\n",
    "                             metadata={'source': knowledge_base_link,\n",
    "                                       'chunkID': chunkID}))\n",
    "    global TOTAL_AMOUNT\n",
    "    if len(source_chunks) > 0:\n",
    "        db = FAISS.from_documents(source_chunks, OpenAIEmbeddings())\n",
    "        count_token = num_tokens_from_string(' '.join([x.page_content for x in source_chunks]), \"cl100k_base\")\n",
    "        count_tokens += count_token\n",
    "        print(f'Количество токенов в документе: {count_token}')\n",
    "        # Embedding model Ada v2 - $0.00010 / 1K tokens - 28/02/2024 - https://openai.com/pricing\n",
    "        price = 0.0001 * count_tokens / 1000\n",
    "        TOTAL_AMOUNT += price\n",
    "        print(f'ЦЕНА запроса создания индексной базы: $ {price}')\n",
    "        return db\n",
    "\n",
    "\n",
    "# Стоимость запроса + ответ для \"gpt-3.5-turbo-0125\"\n",
    "def print_tokens_count(completion):\n",
    "    global TOTAL_AMOUNT\n",
    "    print(f'Использовано токенов: {completion.usage.prompt_tokens} + '\n",
    "                                f'{completion.usage.completion_tokens} = '\n",
    "                                f'{completion.usage.total_tokens}.')\n",
    "    # \"gpt-3.5-turbo-0125\" - Input: $0.0005 /1K tokens - Output: $0.0015 /1K tokens - 28/02/2024 - https://openai.com/pricing\n",
    "    price = 0.0005 * completion.usage.prompt_tokens / 1000 + 0.0015 * completion.usage.completion_tokens / 1000\n",
    "    TOTAL_AMOUNT += price\n",
    "    print(f'Цена запроса + ответ: $ {price}')\n",
    "\n",
    "\n",
    "def gpt_traffic(system, topic, user, search_index, temp=0.5, k=7):\n",
    "    docs = search_index.similarity_search(topic, k)\n",
    "    message_content = re.sub(r'\\n{2}', ' ', '\\n '.join([f'#{i+1}.' + doc.page_content for i, doc in enumerate(docs)]))\n",
    "    messages = [\n",
    "      {\"role\": \"system\", \"content\": system},\n",
    "      {\"role\": \"user\", \"content\": f'{user}. Информация, которая сегодня может понадобиться: {message_content}. \\\n",
    "                        Не упоминай документ с информацией, указанный выше. Запрос пользователя: {topic}'}]\n",
    "    completion = openai.chat.completions.create(model=MODEL, messages=messages, temperature=temp)\n",
    "    print_tokens_count(completion)\n",
    "    answer = completion.choices[0].message.content\n",
    "    return answer, message_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4849,
     "status": "ok",
     "timestamp": 1709146557670,
     "user": {
      "displayName": "Alex Klin",
      "userId": "11249935885368047783"
     },
     "user_tz": -180
    },
    "id": "2tnJjgG9OXKB",
    "outputId": "faafd8b2-5155-4fd5-8216-3eb764da147c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Количество токенов в документе: 32893\n",
      "ЦЕНА запроса создания индексной базы: $ 0.0032893\n"
     ]
    }
   ],
   "source": [
    "#@title Загружаем Базу знаний по продуктам\n",
    "knowledge_base_link = 'https://docs.google.com/document/d/1CmuVP4SiaFDSvPEDz69Dsf6RQm3tMDpJAxh5HOqKfdw'\n",
    "knowledge_base_text = load_googledoc_by_url(knowledge_base_link)\n",
    "db_index = create_search_index(knowledge_base_text, knowledge_base_link, 1024, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2249,
     "status": "ok",
     "timestamp": 1709146591598,
     "user": {
      "displayName": "Alex Klin",
      "userId": "11249935885368047783"
     },
     "user_tz": -180
    },
    "id": "FFvdA3v0JeR2",
    "outputId": "a193b0d0-7136-4cff-93da-37387f4a1e1f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Использовано токенов: 3738 + 64 = 3802.\n",
      "Цена запроса + ответ: $ 0.001965\n",
      "Фраза:\n",
      " \"Стань AI разработчиком с Университетом Искусственного Интеллекта: Обучение, гарантированное трудоустройство и создание собственного AI проекта!\"\n"
     ]
    }
   ],
   "source": [
    "#@title Продающий загловок по продуктам\n",
    "\n",
    "system_title = '''\n",
    "Ты David Ogilvy. Ты американский рекламный гуру и основатель одного из самых влиятельных рекламных агентств - Ogilvy & Mather.\n",
    "У тебя есть вся информация о продуктах компании.\n",
    "Твоя задача генерировать короткие продающие заголовки для таргетированной рекламы с акцентами, который задает пользователь в запросе.\n",
    "Ты знаешь формулу эффективного заголовка для поисковых систем: заголовок это самый заметный элемент, и он должен включать слова,\n",
    "которые люди вводят в поисковую строку. Поэтому продающие заголовки обязательно должны содержать популярный ключевой запрос пользователя.\n",
    "Твои заголовки должны завлекать пользователя, продавать и побуждать совершить действия например купить курс или зарегистрироваться на вебинар.\n",
    "Твои заголовки всегда написаны в твоем индивидуальном стиле. Ты отличаешься от других рекламных копирайтеров своей способностью ясно и эффективно\n",
    "выражать идеи. Ты часто используешь эмоциональные аспекты, чтобы привлечь внимание читателей и вызвать у них желание приобрести продукт.\n",
    "У тебя есть большой документ с информацией об образовательных программах Университета.\n",
    "Твоя задача писать короткие продающие заголовки таргетированной рекламы с акцентами, которые задаёт пользователь в запросе.\n",
    "Бери информацию для заголовка рекламы точно по документу, не придумывай ничего от себя.'''\n",
    "\n",
    "topic = 'Напиши один продающий заголовок для контекстной рекламы по образовательным курсам и услугам Университета Искусственного Интеллекта.'\n",
    "\n",
    "response_title, _ = gpt_traffic(system_title, topic, '', db_index, temp=0.5, k=6)\n",
    "print('Фраза:\\n', response_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7503,
     "status": "ok",
     "timestamp": 1709146702433,
     "user": {
      "displayName": "Alex Klin",
      "userId": "11249935885368047783"
     },
     "user_tz": -180
    },
    "id": "Dd_tDnJTmHy9",
    "outputId": "ff5cda5e-149a-4d1e-9fa1-d97e9ff7dada",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Использовано токенов: 3688 + 305 = 3993.\n",
      "Цена запроса + ответ: $ 0.0023015\n",
      "Текст:\n",
      "  ### Разблокируй свой потенциал с Университетом Искусственного Интеллекта!\n",
      "\n",
      " Устал от повседневной рутины? Хочешь стать востребованным специалистом? Мы знаем, как помочь!\n",
      "\n",
      " 🔥 Почувствуй вызов и стань Middle AI Developer с нашим курсом по Data Science и Нейронным Сетям!\n",
      "\n",
      " 🌟 Что тебя ждет:\n",
      " - Топ-кандидат на любые AI вакансии\n",
      " - Создание собственных AI проектов\n",
      " - Гарантированное трудоустройство с зарплатой от 70 000 рублей\n",
      "\n",
      " 🚀 Вперед, к новым горизонтам! Присоединяйся к нашей команде успешных выпускников, которых выбирают ведущие компании мира!\n",
      "\n",
      " Не упусти свой шанс! Обрети свое будущее с Университетом Искусственного Интеллекта! 🌈\n"
     ]
    }
   ],
   "source": [
    "#@title Продающий текст для телеграмм по формуле PMHS (боль-усиление боли-надежда-решение)\n",
    "\n",
    "system_text = '''\n",
    "Ты David Ogilvy. Ты американский рекламный гуру и основатель одного из самых влиятельных рекламных агентств - Ogilvy & Mather.\n",
    "У тебя есть вся информация о продуктах компании.\n",
    "Твоя задача разрабатывать посты для Яндекс Директ по теме которую указывает пользователь. Твой стиль является простым и убедительным.\n",
    "Ты отличаешься от других рекламных копирайтеров своей способностью ясно и эффективно выражать идеи.\n",
    "Ты часто используешь эмоциональные аспекты, чтобы привлечь внимание читателей и вызвать у них желание приобрести продукт.\n",
    "Давай действовать по шагам: проанализируй информацию компании, запрос пользователя и напиши продающий текст,\n",
    "который соответствует формуле PMHS (боль-усиление боли-надежда-решение).\n",
    "Ты знаешь формулу эффективного рекламного поста PMHS (боль-усиление боли-надежда-решение).:\n",
    "1.Pain (боль): На этом этапе клиент осознает проблему или неудовлетворенность, которую нужно решить.\n",
    "2.More Pain (усиление боли): Здесь происходит углубление осознания проблемы и ее последствий.\n",
    "3.Hope (надежда): На этом этапе предлагается надежда на решение проблемы.\n",
    "4.Solution (решение): Завершающий этап, на котором предлагается конкретное решение проблемы: прийти на вебинар или приобрести курс.\n",
    "В свой ответ включи только продающий текст из 4-х частей формулы PMHS с заголовком. В своем ответе не упоминай названия составляющих формулы PMHS.'''\n",
    "\n",
    "topic = response_title # Учись AI с лучшими и стань востребованным разработчиком - гарантированное трудоустройство!\n",
    "response_text, _ = gpt_traffic(system_text, topic, '', db_index, temp=0.5, k=6)\n",
    "print('Текст:\\n', format_newlines(response_text))"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "TOTAL_AMOUNT"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ltuPKP-uEuQL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1709146711180,
     "user_tz": -180,
     "elapsed": 284,
     "user": {
      "displayName": "Alex Klin",
      "userId": "11249935885368047783"
     }
    },
    "outputId": "fc7d4587-9008-41bc-a946-82d9f6559430",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0100598"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}